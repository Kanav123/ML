{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl = pd.read_csv(\"movie_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#left actor1,actor2,actor3 and director likes,facenumber_in_poster,aspect ratio\n",
    "#left names of cast too mant levels need to see what is to be done\n",
    "continuous_vars = [\n",
    "    'num_critic_for_reviews','gross','duration','num_voted_users','actor_1_facebook_likes',\n",
    "    'actor_2_facebook_likes','actor_3_facebook_likes','director_facebook_likes',\n",
    "    'num_user_for_reviews','budget','title_year','movie_facebook_likes'\n",
    "    ]\n",
    "\n",
    "def preprocess(fl):\n",
    "    for var in continuous_vars:\n",
    "        if var == 'title_year':\n",
    "            fl[var].fillna(fl[var].mode()[0], inplace = 'True')\n",
    "        else:\n",
    "            fl[var].fillna(fl[var].mean(), inplace='True')\n",
    "        for index,row in fl.iterrows():\n",
    "            if row['num_critic_for_reviews']>(140 + 121*3):\n",
    "                val =  140\n",
    "                fl.set_value(index,'num_critic_for_reviews',val)\n",
    "            if row['gross']>(47900000 + 68230000*3):\n",
    "                val =  47900000\n",
    "                fl.set_value(index,'gross',val)\n",
    "            if row['num_voted_users']>(83591 + 138708*3):\n",
    "                val =  83591\n",
    "                fl.set_value(index,'num_voted_users',val)\n",
    "            if row['actor_1_facebook_likes']>(6583 + 15713*3):\n",
    "                val =  6583\n",
    "                fl.set_value(index,'actor_1_facebook_likes',val)\n",
    "            if row['actor_2_facebook_likes']>(1643 + 4124*3):\n",
    "                val =  1643\n",
    "                fl.set_value(index,'actor_2_facebook_likes',val)\n",
    "            if row['actor_3_facebook_likes']>(643 + 1689*3):\n",
    "                val =  643\n",
    "                fl.set_value(index,'actor_3_facebook_likes',val)\n",
    "            if row['director_facebook_likes']>(681 + 2809*3):\n",
    "                val =  681\n",
    "                fl.set_value(index,'director_facebook_likes',val)\n",
    "            if row['num_user_for_reviews']>(271 + 373*3):\n",
    "                val =  271\n",
    "                fl.set_value(index,'num_user_for_reviews',val)\n",
    "            if row['budget']>(40612860 + 222575500*3):\n",
    "                val =  40612860\n",
    "                fl.set_value(index,'budget',val)\n",
    "            if row['duration']>(107 + 25*3):\n",
    "                val =  107\n",
    "                fl.set_value(index,'budget',val)\n",
    "            if row['movie_facebook_likes']>(7638 + 19805*3):\n",
    "                val =  7638\n",
    "                fl.set_value(index,'movie_facebook_likes',val)\n",
    "\n",
    "#def normalize(fl):\n",
    "    #if some other model than rf has to be used\n",
    "                    \n",
    "preprocess(fl)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "list_genres = []\n",
    "for index,row in fl.iterrows():\n",
    "    genre = (\" \").join(row['genres'].split('|'))\n",
    "    list_genres.append(genre)\n",
    "count_vectorizer.fit_transform(list_genres) #for test data also   \n",
    "categorical_vars = ['content_rating','language']\n",
    "text_vars = ['genres','plot_keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'tv': 27, 'romance': 21, 'documentary': 6, 'show': 24, 'drama': 7, 'crime': 5, 'comedy': 4, 'mystery': 17, 'film': 11, 'animation': 2, 'action': 0, 'family': 8, 'fantasy': 9, 'noir': 19, 'fi': 10, 'music': 15, 'reality': 20, 'game': 12, 'news': 18, 'war': 28, 'sport': 25, 'adventure': 1, 'western': 29, 'history': 13, 'sci': 22, 'biography': 3, 'musical': 16, 'thriller': 26, 'horror': 14, 'short': 23}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\", count_vectorizer.vocabulary_)\n",
    "freq_term_matrix = count_vectorizer.transform(list_genres)\n",
    "dt = freq_term_matrix.todense()\n",
    "import operator\n",
    "sorted_cols = sorted(count_vectorizer.vocabulary_.items(), key=operator.itemgetter(1))\n",
    "cols= []\n",
    "for col in sorted_cols:\n",
    "    cols.append(col[0])\n",
    "df_genre_words = pd.DataFrame(data=dt[0:,0:],columns= cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncount_vectorizer1 = CountVectorizer()\\nlist_pk = []\\nfor index,row in fl.iterrows():\\n    pk = (\" \").join(str(row[\\'plot_keywords\\']).split(\\'|\\'))\\n    list_pk.append(pk)\\ncount_vectorizer1.fit_transform(list_pk) #for test data also   \\ncategorical_vars = [\\'country\\',\\'content_rating\\']\\ntext_vars = [\\'genres\\',\\'plot_keywords\\']\\nprint(\"Vocabulary:\", count_vectorizer1.vocabulary_)\\nfreq_term_matrix = count_vectorizer.transform(list_pk)\\nprint(freq_term_matrix.todense().shape)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "count_vectorizer1 = CountVectorizer()\n",
    "list_pk = []\n",
    "for index,row in fl.iterrows():\n",
    "    pk = (\" \").join(str(row['plot_keywords']).split('|'))\n",
    "    list_pk.append(pk)\n",
    "count_vectorizer1.fit_transform(list_pk) #for test data also   \n",
    "categorical_vars = ['country','content_rating']\n",
    "text_vars = ['genres','plot_keywords']\n",
    "print(\"Vocabulary:\", count_vectorizer1.vocabulary_)\n",
    "freq_term_matrix = count_vectorizer.transform(list_pk)\n",
    "print(freq_term_matrix.todense().shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#handle categoricals\n",
    "#not using langauge as low importance\n",
    "def preprocess(fl):\n",
    "    for feature in categorical_vars:\n",
    "        dummies = pd.get_dummies(fl[feature])\n",
    "        fl= pd.concat([fl, dummies], axis= 1 )\n",
    "        fl = fl.drop(feature, 1)\n",
    "    return fl\n",
    "fl = preprocess(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge all the df's and remove note to be used vars\n",
    "df_train= pd.concat([fl , df_genre_words], axis= 1 )\n",
    "df_train = df_train.drop(['color','director_name','actor_2_name','actor_3_name','plot_keywords','country'\n",
    "                         ,'aspect_ratio','actor_1_name','genres','facenumber_in_poster','movie_imdb_link'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('imdb_processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
